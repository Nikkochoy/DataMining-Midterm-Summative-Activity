{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71b9c49b",
   "metadata": {},
   "source": [
    "# Twitter Scraping script\n",
    "\n",
    "Running this file would scrape twitter to get content of tweets\n",
    "\n",
    "`Don't forget to install libraries!`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13b3e3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Sleeping for 237 seconds.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Username</th>\n",
       "      <th>Date Created</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>El jefe</td>\n",
       "      <td>SoylaJefe</td>\n",
       "      <td>2025-06-29 13:02:19+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Riddle me this climate clowns... why in most c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anvesha</td>\n",
       "      <td>p_pezzonovante</td>\n",
       "      <td>2025-06-29 12:52:08+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>The world is in such a bad place that climate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gemma Elliott</td>\n",
       "      <td>drgemmaelliott</td>\n",
       "      <td>2025-06-29 12:36:04+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Fresh climate emergency hellscape is that (all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Orville Bartuska</td>\n",
       "      <td>orville67416</td>\n",
       "      <td>2025-06-29 12:24:08+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Our digital habits leave a big environmental m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Đoàn Tần</td>\n",
       "      <td>doantan137</td>\n",
       "      <td>2025-06-29 11:53:09+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Renewable energy refers to energy derived from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Vins</td>\n",
       "      <td>Vinitaa890</td>\n",
       "      <td>2025-06-27 03:56:06+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>From reducing carbon emissions to increasing c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Mortimer</td>\n",
       "      <td>mortimer_1</td>\n",
       "      <td>2025-06-27 03:43:36+00:00</td>\n",
       "      <td>679</td>\n",
       "      <td>The Canadian and BC gov’t lecture Canadians ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Alana Shepherd</td>\n",
       "      <td>shepherd_a51338</td>\n",
       "      <td>2025-06-27 02:05:06+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>The burning police car pollutes the environmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Carl Martin</td>\n",
       "      <td>CarlMartin99589</td>\n",
       "      <td>2025-06-27 02:01:50+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>The international agreement aims to reduce car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Trần Phương Quỳnh</td>\n",
       "      <td>TrnPhngQun69996</td>\n",
       "      <td>2025-06-27 01:29:20+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Climate change poses a major threat to the pla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 User         Username              Date Created  Likes  \\\n",
       "0             El jefe        SoylaJefe 2025-06-29 13:02:19+00:00      0   \n",
       "1             Anvesha   p_pezzonovante 2025-06-29 12:52:08+00:00      1   \n",
       "2       Gemma Elliott   drgemmaelliott 2025-06-29 12:36:04+00:00      0   \n",
       "3    Orville Bartuska     orville67416 2025-06-29 12:24:08+00:00      0   \n",
       "4            Đoàn Tần       doantan137 2025-06-29 11:53:09+00:00      0   \n",
       "..                ...              ...                       ...    ...   \n",
       "95               Vins       Vinitaa890 2025-06-27 03:56:06+00:00      0   \n",
       "96           Mortimer       mortimer_1 2025-06-27 03:43:36+00:00    679   \n",
       "97     Alana Shepherd  shepherd_a51338 2025-06-27 02:05:06+00:00      1   \n",
       "98        Carl Martin  CarlMartin99589 2025-06-27 02:01:50+00:00      0   \n",
       "99  Trần Phương Quỳnh  TrnPhngQun69996 2025-06-27 01:29:20+00:00      0   \n",
       "\n",
       "                                                Tweet  \n",
       "0   Riddle me this climate clowns... why in most c...  \n",
       "1   The world is in such a bad place that climate ...  \n",
       "2   Fresh climate emergency hellscape is that (all...  \n",
       "3   Our digital habits leave a big environmental m...  \n",
       "4   Renewable energy refers to energy derived from...  \n",
       "..                                                ...  \n",
       "95  From reducing carbon emissions to increasing c...  \n",
       "96  The Canadian and BC gov’t lecture Canadians ab...  \n",
       "97  The burning police car pollutes the environmen...  \n",
       "98  The international agreement aims to reduce car...  \n",
       "99  Climate change poses a major threat to the pla...  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "from configparser import ConfigParser\n",
    "import csv\n",
    "\n",
    "# API Config\n",
    "config = ConfigParser(interpolation=None)\n",
    "config.read('../config.ini')\n",
    "BEARER_TOKEN = config['keys']['BEARER_TOKEN']\n",
    "consumer_key = config['keys']['CONSUMER_KEY']\n",
    "consumer_secret = config['keys']['CONSUMER_SECRET']\n",
    "access_token = config['keys']['ACCESS_TOKEN']\n",
    "access_token_secret = config['keys']['ACCESS_TOKEN_SECRET']\n",
    "\n",
    "client = tweepy.Client(\n",
    "    bearer_token=BEARER_TOKEN,\n",
    "    wait_on_rate_limit=True\n",
    ")\n",
    "\n",
    "# Define search parameters\n",
    "search_query = '(\"climate emergency\" OR \"carbon emissions\") -is:retweet -is:reply -has:links lang:en'\n",
    "no_of_tweets = 100\n",
    "\n",
    "try:\n",
    "    # Fetch\n",
    "    tweets = client.search_recent_tweets(\n",
    "        query=search_query,\n",
    "        max_results=no_of_tweets,\n",
    "        tweet_fields=['created_at', 'public_metrics', 'text'],\n",
    "        user_fields=['name', 'username'],\n",
    "        expansions=['author_id']\n",
    "    )\n",
    "    \n",
    "    # Extract users data\n",
    "    users = {u.id: u for u in tweets.includes['users']}\n",
    "    \n",
    "    # Prepare tweet data\n",
    "    tweets_data = []\n",
    "    for tweet in tweets.data:\n",
    "        user = users[tweet.author_id]\n",
    "        tweets_data.append({\n",
    "            \"User\": user.name,\n",
    "            \"Username\": user.username,\n",
    "            \"Date Created\": tweet.created_at,\n",
    "            \"Likes\": tweet.public_metrics['like_count'],\n",
    "            \"Tweet\": tweet.text\n",
    "        })\n",
    "    \n",
    "    # Create DataFrame\n",
    "    tweets_df = pd.DataFrame(tweets_data)\n",
    "    \n",
    "except tweepy.TweepyException as e:\n",
    "    print(f\"API Error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"General Error: {e}\")\n",
    "\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7284cb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 100 tweets to tweet_content6.csv\n"
     ]
    }
   ],
   "source": [
    "tweets_df.to_csv('../data/scraped/tweet_content6.csv', index=False, quoting=csv.QUOTE_ALL, encoding='utf-8')\n",
    "print(f\"Saved {len(tweets_df)} tweets to tweet_content6.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7231f2e4",
   "metadata": {},
   "source": [
    "### Merge all scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d07342bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: ../Data\\tweets_content.csv | Rows: 100\n",
      "Processed: ../Data\\tweet_content2.csv | Rows: 100\n",
      "Processed: ../Data\\tweet_content3.csv | Rows: 3\n",
      "Processed: ../Data\\tweet_content4.csv | Rows: 100\n",
      "Processed: ../Data\\tweet_content5.csv | Rows: 38\n",
      "Processed: ../Data\\tweet_content6.csv | Rows: 100\n",
      "Processed: ../Data\\tweet_details.csv | Rows: 99\n",
      "\n",
      "Merging complete!\n",
      "Total files merged: 7\n",
      "Total rows in merged file: 540\n",
      "Merged file saved to: ../Data\\merged_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# 1. Set your directory path containing the CSV files\n",
    "input_dir = \"../data/scraped\"\n",
    "\n",
    "# 2. Get all CSV files in the directory\n",
    "all_csv_files = glob.glob(os.path.join(input_dir, \"*.csv\"))\n",
    "\n",
    "# 3. Verify we have exactly 7 files (optional)\n",
    "if len(all_csv_files) != 7:\n",
    "    print(f\"Found {len(all_csv_files)} files instead of 7. Continuing anyway...\")\n",
    "\n",
    "# 4. Create an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# 5. Read each CSV file and append to the list\n",
    "for csv_file in all_csv_files:\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file)\n",
    "        # Add filename as a column to track source (optional)\n",
    "        df['source_file'] = os.path.basename(csv_file)\n",
    "        dfs.append(df)\n",
    "        print(f\"Processed: {csv_file} | Rows: {len(df)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {csv_file}: {str(e)}\")\n",
    "\n",
    "# 6. Concat all DataFrames\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# 7. Save the merged DataFrame to a new CSV file\n",
    "output_path = os.path.join(\"../data\", \"tweets.csv\")\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"\\nMerging complete!\")\n",
    "print(f\"Total files merged: {len(dfs)}\")\n",
    "print(f\"Total rows in merged file: {len(merged_df)}\")\n",
    "print(f\"Merged file saved to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
